{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-siino/GM_SOURCE_CODE/blob/main/NVIDIA_DS/ERROR_ANALYSIS_GM_NVIDIA_DistilBERT_Zero_Shot_Fine_Tuned_multiclass_classification_MSiino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4DW7kiug94o"
      },
      "source": [
        "# Fine Tuning Transformer for MultiClass Text Classification of Source Code. Notebook by Marco Siino et al."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJOVl9vLg94q"
      },
      "source": [
        "# Importing Python Libraries and preparing the environment\n",
        "\n",
        "At this step we will be importing the libraries and modules needed to run our script. Libraries are:\n",
        "* Pandas\n",
        "* Pytorch\n",
        "* Pytorch Utils for Dataset and Dataloader\n",
        "* Transformers\n",
        "* BERT Model and Tokenizer\n",
        "\n",
        "Followed by that we will preapre the device for CUDA execeution. This configuration is needed if you want to leverage on onboard GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wuMlXT80GAMK"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel, DistilBertModel, DistilBertTokenizer\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xQMKTZ4ARk12"
      },
      "outputs": [],
      "source": [
        "# Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNOPbPvVg94s"
      },
      "source": [
        "# Importing and Pre-Processing the domain data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iNCaZ2epNcSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2aaf26-8561-40c5-fc60-778785582153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   src oracle  ENCODE_CAT\n",
            "0    2048 - 255 - __kernel void A(int a, const __gl...    GPU           1\n",
            "1    131072 - 256 - __kernel void A(__global uint* ...    GPU           1\n",
            "2    3145728 - 256 - extern void B(float4 a, float4...    GPU           1\n",
            "3    4096 - 256 - __kernel void A(__global float* a...    GPU           1\n",
            "4    524288 - 256 - __kernel void A(__global uint* ...    CPU           0\n",
            "..                                                 ...    ...         ...\n",
            "675  2000628 - 128 - __kernel void A(__global const...    CPU           0\n",
            "676  2000628 - 128 - __kernel void A(__global const...    CPU           0\n",
            "677  71647488 - 0 - extern int D(__private int, __p...    CPU           0\n",
            "678  71647488 - 256 - extern int B(int, int, int);\\...    CPU           0\n",
            "679  117440512 - 128 - __kernel void A(__global con...    CPU           0\n",
            "\n",
            "[680 rows x 3 columns]\n",
            "                                                   src oracle  ENCODE_CAT\n",
            "0    6346800 - 52 - __kernel void A(__global double...    CPU           0\n",
            "1    15949464 - 48 - __kernel void A(__global const...    GPU           1\n",
            "2    14742140 - 128 - extern double __clc_pow(const...    CPU           0\n",
            "3    15948384 - 2 - extern void B(double m, double ...    CPU           0\n",
            "4    755867256 - 64 - __kernel void A(__global doub...    GPU           1\n",
            "..                                                 ...    ...         ...\n",
            "675  14742140 - 128 - __kernel void A(__global doub...    GPU           1\n",
            "676  57594120 - 128 - __kernel void A(__global cons...    CPU           0\n",
            "677  320454824 - 64 - extern void B(double, double,...    GPU           1\n",
            "678  1344811536 - 26 - extern void D(__private doub...    GPU           1\n",
            "679  1313673512 - 32 - __kernel void A(__global con...    GPU           1\n",
            "\n",
            "[680 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Import the csv into pandas dataframe and add the headers\n",
        "\n",
        "df = pd.read_csv('dataset-devmap-nvidia.csv',sep=',')\n",
        "#df = pd.concat(map(pd.read_csv, ['dataset-devmap-nvidia.csv', 'dataset-devmap-amd.csv']))\n",
        "#df = pd.read_csv('dataset-devmap-nvidia.csv', sep='\\t', names=['benchmark','dataset','comp','rational','mem','localmem','coalesced','atomic','transfer','wgsize','oracle','runtime_cpu','runtime_gpu','src','seq'])\n",
        "#print(df.head())\n",
        "# Now include transfer and wgsize columns into the src column.\n",
        "df['src'] = df['transfer'].astype(str) +\" - \"+ df['wgsize'].astype(str) +\" - \"+df[\"src\"]\n",
        "# # Removing unwanted columns and only leaving title of news and the category which will be the target\n",
        "df = df[['src','oracle']]\n",
        "#print(df.head())\n",
        "\n",
        "encode_dict = {}\n",
        "\n",
        "def encode_cat(x):\n",
        "    if x == \"GPU\":\n",
        "      encode_dict[x]=1\n",
        "    else:\n",
        "      encode_dict[x]=0\n",
        "    return encode_dict[x]\n",
        "\n",
        "df['ENCODE_CAT'] = df['oracle'].apply(lambda x: encode_cat(x))\n",
        "\n",
        "print(df)\n",
        "\n",
        "df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('shuffled_df.csv')"
      ],
      "metadata": {
        "id": "kBKBmr8T0Cwm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDomDFc5g94s"
      },
      "source": [
        "# Preparing the Dataset and Dataloader\n",
        "\n",
        "We will start with defining few key variables that will be used later during the training/fine tuning stage.\n",
        "Followed by creation of Dataset class - This defines how the text is pre-processed before sending it to the neural network. We will also define the Dataloader that will feed  the data in batches to the neural network for suitable training and processing.\n",
        "Dataset and Dataloader are constructs of the PyTorch library for defining and controlling the data pre-processing and its passage to neural network. For further reading into Dataset and Dataloader read the [docs at PyTorch](https://pytorch.org/docs/stable/data.html)\n",
        "\n",
        "#### *Triage* Dataset Class\n",
        "- This class is defined to accept the Dataframe as input and generate tokenized output that is used by the DistilBERT model for training.\n",
        "- We are using the DistilBERT tokenizer to tokenize the data in the `TITLE` column of the dataframe.\n",
        "- The tokenizer uses the `encode_plus` method to perform tokenization and generate the necessary outputs, namely: `ids`, `attention_mask`\n",
        "- To read further into the tokenizer, [refer to this document](https://huggingface.co/transformers/model_doc/distilbert.html#distilberttokenizer)\n",
        "- `target` is the encoded category on the news headline.\n",
        "- The *Triage* class is used to create 2 datasets, for training and for validation.\n",
        "- *Training Dataset* is used to fine tune the model: **80% of the original data**\n",
        "- *Validation Dataset* is used to evaluate the performance of the model. The model has not seen this data during training.\n",
        "\n",
        "#### Dataloader\n",
        "- Dataloader is used to for creating training and validation dataloader that load data to the neural network in a defined manner. This is needed because all the data from the dataset cannot be loaded to the memory at once, hence the amount of dataloaded to the memory and then passed to the neural network needs to be controlled.\n",
        "- This control is achieved using the parameters such as `batch_size` and `max_len`.\n",
        "- Training and Validation dataloaders are used in the training and validation part of the flow respectively"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RIMPIAZZO MCROCK\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 1\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-05\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert/distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "JhA_AVEdrxWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eaf2c04-45fe-480a-83d0-545b09c3ab8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2vX7kzaAHu39"
      },
      "outputs": [],
      "source": [
        "class Triage(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.data.src[index])\n",
        "        title = \" \".join(title.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.data.ENCODE_CAT[index], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSRhkzXKg94u"
      },
      "source": [
        "# Creating the Transformer for Fine Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
        "\n",
        "class DistillBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistillBERTClass, self).__init__()\n",
        "        self.l1 = DistilBertModel.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "JYdlFn3z114Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate the 5 fold objects."
      ],
      "metadata": {
        "id": "L5GIoLhYyY79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Each i-train fold can be accessed with df_train[i]. Same for test.\n",
        "fold_nr = 5\n",
        "\n",
        "kf = KFold(n_splits=5, random_state=None, shuffle=False)\n",
        "\n",
        "df_train = []\n",
        "df_test = []\n",
        "model = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(df)):\n",
        "  df_train.append(df.iloc[train_index])\n",
        "  df_test.append(df.iloc[test_index])\n",
        "# print(df_train[0])\n",
        "\n",
        "for i in range(0,fold_nr):\n",
        "  df_train[i] = df_train[i].reset_index(drop=True)\n",
        "  df_test[i] = df_test[i].reset_index(drop=True)\n",
        "  # Generate a different model for each fold.\n",
        "  model.append(DistillBERTClass())\n",
        "  model[i].to(device)\n"
      ],
      "metadata": {
        "id": "Dx0eqM-Gynq4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Zcwq13c0NE9c"
      },
      "outputs": [],
      "source": [
        "# Creating the dataset and dataloader\n",
        "\n",
        "#train_size = 0.8\n",
        "#train_dataset=df.sample(frac=train_size,random_state=200)\n",
        "#test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "#train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "#print(\"FULL Dataset: {}\".format(df.shape))\n",
        "#print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "#print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "#training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
        "#testing_set = Triage(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "training_set = []\n",
        "testing_set = []\n",
        "training_loader = []\n",
        "testing_loader = []\n",
        "\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "\n",
        "for i in range(0,fold_nr):\n",
        "  training_set.append(Triage(df_train[i], tokenizer, MAX_LEN))\n",
        "  testing_set.append(Triage(df_test[i], tokenizer, MAX_LEN))\n",
        "  training_loader.append(DataLoader(training_set[i], **train_params))\n",
        "  testing_loader.append(DataLoader(testing_set[i], **test_params))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate accuracy"
      ],
      "metadata": {
        "id": "E6vJBtdSMOC1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U3U4s3e9g94u"
      },
      "outputs": [],
      "source": [
        "# Function to calcuate the accuracy of the model\n",
        "\n",
        "def calcuate_accu(big_idx, targets):\n",
        "    n_correct = (big_idx==targets).sum().item()\n",
        "    return n_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fF3XpswUg94u"
      },
      "outputs": [],
      "source": [
        "# Creating the loss function and optimizer\n",
        "optimizer = []\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "for i in range(0,fold_nr):\n",
        "  optimizer.append(torch.optim.Adam(params =  model[i].parameters(), lr=LEARNING_RATE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBcni6oig94u"
      },
      "source": [
        "# Define the Fine Tuning of the Model\n",
        "\n",
        "After all the effort of loading and preparing the data and datasets, creating the model and defining its loss and optimizer. This is probably the easier steps in the process.\n",
        "\n",
        "Here we define a training function that trains the model on the training dataset created above, specified number of times (EPOCH), An epoch defines how many times the complete data will be passed through the network.\n",
        "\n",
        "Following events happen in this function to fine tune the neural network:\n",
        "- The dataloader passes data to the model based on the batch size.\n",
        "- Subsequent output from the model and the actual category are compared to calculate the loss.\n",
        "- Loss value is used to optimize the weights of the neurons in the network.\n",
        "- After every 5000 steps the loss value is printed in the console."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QYzhifllg94u"
      },
      "outputs": [],
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
        "\n",
        "def train(epoch, model,optimizer, training_loader):\n",
        "    tr_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(ids, mask)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        tr_loss += loss.item()\n",
        "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "        n_correct += calcuate_accu(big_idx, targets)\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples+=targets.size(0)\n",
        "\n",
        "        if _%5000==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            accu_step = (n_correct*100)/nb_tr_examples\n",
        "            print(f\"\\nTraining Loss per 5000 steps: {loss_step}\")\n",
        "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # # When using GPU\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-Shot evaluation on the 5 fold."
      ],
      "metadata": {
        "id": "zNMpIcGYTyu_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KzL51A5qg94v"
      },
      "outputs": [],
      "source": [
        "\n",
        "def valid(model, testing_loader):\n",
        "    tr_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.eval()\n",
        "    n_correct = 0; n_wrong = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            #print(\"\\n\\nSTEP Nr. \", nb_tr_steps)\n",
        "            # Validation batch is 2. Then, every step is 2 predictions. Then the total steps are half of the size of the test fold.\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.long)\n",
        "            #print(\"ids è\", ids)\n",
        "            #print(\"mask è\", mask)\n",
        "            outputs = model(ids, mask).squeeze()\n",
        "            #print(\"gli outputs sono:\",outputs)\n",
        "            #print(\"i targets sono:\",targets)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            tr_loss += loss.item()\n",
        "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "            n_correct += calcuate_accu(big_idx, targets)\n",
        "\n",
        "            #print(\"bid_idx è\",big_idx)\n",
        "            #print(\"Correct now is:\", n_correct)\n",
        "\n",
        "            nb_tr_steps += 1\n",
        "            nb_tr_examples+=targets.size(0)\n",
        "\n",
        "            if _%5000==0:\n",
        "                loss_step = tr_loss/nb_tr_steps\n",
        "                accu_step = (n_correct*100)/nb_tr_examples\n",
        "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
        "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return epoch_accu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-xBmWV93g94v",
        "outputId": "3d717b59-b65c-4167-c2d6-3cfa946dd4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the validation section to print the accuracy and see how it performs\n",
            "Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n",
            "\n",
            "Entering FOLD NR.  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "size mismatch (got input: [2], target: [1])",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-fcab10dd072d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold_nr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEntering FOLD NR. \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy on test data = %0.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-952410143791>\u001b[0m in \u001b[0;36mvalid\u001b[0;34m(model, testing_loader)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m#print(\"gli outputs sono:\",outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#print(\"i targets sono:\",targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mbig_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch (got input: [2], target: [1])"
          ]
        }
      ],
      "source": [
        "print('This is the validation section to print the accuracy and see how it performs')\n",
        "print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n",
        "for i in range(0,fold_nr):\n",
        "  print(\"\\nEntering FOLD NR. \", i)\n",
        "  acc = valid(model[i], testing_loader[i])\n",
        "  print(\"Accuracy on test data = %0.2f%%\" % acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning the model."
      ],
      "metadata": {
        "id": "lX5GVxBdUHtr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZMfM4AVNg94v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d16431d-a2a9-47c1-9019-056d1d1472aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entering FOLD NR.  0\n",
            "\n",
            "Training Loss per 5000 steps: 0.7406401634216309\n",
            "Training Accuracy per 5000 steps: 25.0\n",
            "The Total Accuracy for Epoch 0: 65.25735294117646\n",
            "Training Loss Epoch: 0.6315617107731455\n",
            "Training Accuracy Epoch: 65.25735294117646\n",
            "\n",
            "Training Loss per 5000 steps: 0.5124740600585938\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 1: 77.94117647058823\n",
            "Training Loss Epoch: 0.4833662713165669\n",
            "Training Accuracy Epoch: 77.94117647058823\n",
            "\n",
            "Training Loss per 5000 steps: 0.28884607553482056\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 2: 83.63970588235294\n",
            "Training Loss Epoch: 0.36627116815789657\n",
            "Training Accuracy Epoch: 83.63970588235294\n",
            "\n",
            "Training Loss per 5000 steps: 0.8889967203140259\n",
            "Training Accuracy per 5000 steps: 50.0\n",
            "The Total Accuracy for Epoch 3: 87.13235294117646\n",
            "Training Loss Epoch: 0.2910846232313334\n",
            "Training Accuracy Epoch: 87.13235294117646\n",
            "\n",
            "Training Loss per 5000 steps: 0.5119920372962952\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 4: 88.6029411764706\n",
            "Training Loss Epoch: 0.25346475973834887\n",
            "Training Accuracy Epoch: 88.6029411764706\n",
            "\n",
            "Training Loss per 5000 steps: 0.4180929362773895\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 5: 90.99264705882354\n",
            "Training Loss Epoch: 0.2470606720136643\n",
            "Training Accuracy Epoch: 90.99264705882354\n",
            "\n",
            "Training Loss per 5000 steps: 0.11884374171495438\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 6: 90.99264705882354\n",
            "Training Loss Epoch: 0.21910974661381366\n",
            "Training Accuracy Epoch: 90.99264705882354\n",
            "\n",
            "Training Loss per 5000 steps: 0.18358147144317627\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 7: 93.56617647058823\n",
            "Training Loss Epoch: 0.15073310807415777\n",
            "Training Accuracy Epoch: 93.56617647058823\n",
            "\n",
            "Training Loss per 5000 steps: 0.7783780694007874\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 8: 93.56617647058823\n",
            "Training Loss Epoch: 0.15244328965576748\n",
            "Training Accuracy Epoch: 93.56617647058823\n",
            "\n",
            "Training Loss per 5000 steps: 0.359942764043808\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 9: 94.48529411764706\n",
            "Training Loss Epoch: 0.13079623979694374\n",
            "Training Accuracy Epoch: 94.48529411764706\n",
            "\n",
            "Entering FOLD NR.  1\n",
            "\n",
            "Training Loss per 5000 steps: 0.7030508518218994\n",
            "Training Accuracy per 5000 steps: 50.0\n",
            "The Total Accuracy for Epoch 0: 54.044117647058826\n",
            "Training Loss Epoch: 0.6876380290178692\n",
            "Training Accuracy Epoch: 54.044117647058826\n",
            "\n",
            "Training Loss per 5000 steps: 0.558504045009613\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 1: 64.33823529411765\n",
            "Training Loss Epoch: 0.6179200619020883\n",
            "Training Accuracy Epoch: 64.33823529411765\n",
            "\n",
            "Training Loss per 5000 steps: 0.4278692305088043\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 2: 75.55147058823529\n",
            "Training Loss Epoch: 0.5148726626682807\n",
            "Training Accuracy Epoch: 75.55147058823529\n",
            "\n",
            "Training Loss per 5000 steps: 0.47121620178222656\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 3: 78.86029411764706\n",
            "Training Loss Epoch: 0.435197305317749\n",
            "Training Accuracy Epoch: 78.86029411764706\n",
            "\n",
            "Training Loss per 5000 steps: 0.7936624884605408\n",
            "Training Accuracy per 5000 steps: 50.0\n",
            "The Total Accuracy for Epoch 4: 84.55882352941177\n",
            "Training Loss Epoch: 0.3539458448889063\n",
            "Training Accuracy Epoch: 84.55882352941177\n",
            "\n",
            "Training Loss per 5000 steps: 0.258212685585022\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 5: 89.5220588235294\n",
            "Training Loss Epoch: 0.26703179219518514\n",
            "Training Accuracy Epoch: 89.5220588235294\n",
            "\n",
            "Training Loss per 5000 steps: 0.06340846419334412\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 6: 91.17647058823529\n",
            "Training Loss Epoch: 0.2235638116732897\n",
            "Training Accuracy Epoch: 91.17647058823529\n",
            "\n",
            "Training Loss per 5000 steps: 0.028562044724822044\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 7: 91.91176470588235\n",
            "Training Loss Epoch: 0.21855139641967766\n",
            "Training Accuracy Epoch: 91.91176470588235\n",
            "\n",
            "Training Loss per 5000 steps: 0.4505240023136139\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 8: 94.30147058823529\n",
            "Training Loss Epoch: 0.16993005611413323\n",
            "Training Accuracy Epoch: 94.30147058823529\n",
            "\n",
            "Training Loss per 5000 steps: 0.01722383126616478\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 9: 94.8529411764706\n",
            "Training Loss Epoch: 0.1541410867973943\n",
            "Training Accuracy Epoch: 94.8529411764706\n",
            "\n",
            "Entering FOLD NR.  2\n",
            "\n",
            "Training Loss per 5000 steps: 0.7144737243652344\n",
            "Training Accuracy per 5000 steps: 50.0\n",
            "The Total Accuracy for Epoch 0: 55.6985294117647\n",
            "Training Loss Epoch: 0.68029144932242\n",
            "Training Accuracy Epoch: 55.6985294117647\n",
            "\n",
            "Training Loss per 5000 steps: 0.5349815487861633\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 1: 70.7720588235294\n",
            "Training Loss Epoch: 0.582819597576471\n",
            "Training Accuracy Epoch: 70.7720588235294\n",
            "\n",
            "Training Loss per 5000 steps: 0.46143752336502075\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 2: 80.1470588235294\n",
            "Training Loss Epoch: 0.4381025416557403\n",
            "Training Accuracy Epoch: 80.1470588235294\n",
            "\n",
            "Training Loss per 5000 steps: 0.16328200697898865\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 3: 86.21323529411765\n",
            "Training Loss Epoch: 0.3170588227427181\n",
            "Training Accuracy Epoch: 86.21323529411765\n",
            "\n",
            "Training Loss per 5000 steps: 0.29223090410232544\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 4: 88.41911764705883\n",
            "Training Loss Epoch: 0.3075234639896628\n",
            "Training Accuracy Epoch: 88.41911764705883\n",
            "\n",
            "Training Loss per 5000 steps: 0.16543063521385193\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 5: 90.07352941176471\n",
            "Training Loss Epoch: 0.23718663561157882\n",
            "Training Accuracy Epoch: 90.07352941176471\n",
            "\n",
            "Training Loss per 5000 steps: 0.1281706839799881\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 6: 93.75\n",
            "Training Loss Epoch: 0.16214694634682553\n",
            "Training Accuracy Epoch: 93.75\n",
            "\n",
            "Training Loss per 5000 steps: 0.025170642882585526\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 7: 95.58823529411765\n",
            "Training Loss Epoch: 0.1146918797167018\n",
            "Training Accuracy Epoch: 95.58823529411765\n",
            "\n",
            "Training Loss per 5000 steps: 0.028044460341334343\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 8: 94.66911764705883\n",
            "Training Loss Epoch: 0.1361213155049721\n",
            "Training Accuracy Epoch: 94.66911764705883\n",
            "\n",
            "Training Loss per 5000 steps: 0.4791775047779083\n",
            "Training Accuracy per 5000 steps: 50.0\n",
            "The Total Accuracy for Epoch 9: 95.95588235294117\n",
            "Training Loss Epoch: 0.09035012802547392\n",
            "Training Accuracy Epoch: 95.95588235294117\n",
            "\n",
            "Entering FOLD NR.  3\n",
            "\n",
            "Training Loss per 5000 steps: 0.6764357089996338\n",
            "Training Accuracy per 5000 steps: 50.0\n",
            "The Total Accuracy for Epoch 0: 61.029411764705884\n",
            "Training Loss Epoch: 0.6612402378197979\n",
            "Training Accuracy Epoch: 61.029411764705884\n",
            "\n",
            "Training Loss per 5000 steps: 0.47206932306289673\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 1: 75.0\n",
            "Training Loss Epoch: 0.5513562574325239\n",
            "Training Accuracy Epoch: 75.0\n",
            "\n",
            "Training Loss per 5000 steps: 0.32173100113868713\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 2: 79.2279411764706\n",
            "Training Loss Epoch: 0.4363793088671039\n",
            "Training Accuracy Epoch: 79.2279411764706\n",
            "\n",
            "Training Loss per 5000 steps: 0.42022037506103516\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 3: 83.45588235294117\n",
            "Training Loss Epoch: 0.36677884874755845\n",
            "Training Accuracy Epoch: 83.45588235294117\n",
            "\n",
            "Training Loss per 5000 steps: 0.18955804407596588\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 4: 89.33823529411765\n",
            "Training Loss Epoch: 0.27151090520269733\n",
            "Training Accuracy Epoch: 89.33823529411765\n",
            "\n",
            "Training Loss per 5000 steps: 0.08789201825857162\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 5: 92.27941176470588\n",
            "Training Loss Epoch: 0.1848452249131001\n",
            "Training Accuracy Epoch: 92.27941176470588\n",
            "\n",
            "Training Loss per 5000 steps: 0.18009909987449646\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 6: 93.93382352941177\n",
            "Training Loss Epoch: 0.1826384787050569\n",
            "Training Accuracy Epoch: 93.93382352941177\n",
            "\n",
            "Training Loss per 5000 steps: 0.5041449666023254\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 7: 93.19852941176471\n",
            "Training Loss Epoch: 0.1654483051491244\n",
            "Training Accuracy Epoch: 93.19852941176471\n",
            "\n",
            "Training Loss per 5000 steps: 0.035465650260448456\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 8: 95.58823529411765\n",
            "Training Loss Epoch: 0.12796398236840853\n",
            "Training Accuracy Epoch: 95.58823529411765\n",
            "\n",
            "Training Loss per 5000 steps: 0.01186717115342617\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 9: 95.40441176470588\n",
            "Training Loss Epoch: 0.12554152403711616\n",
            "Training Accuracy Epoch: 95.40441176470588\n",
            "\n",
            "Entering FOLD NR.  4\n",
            "\n",
            "Training Loss per 5000 steps: 0.7084148526191711\n",
            "Training Accuracy per 5000 steps: 50.0\n",
            "The Total Accuracy for Epoch 0: 55.88235294117647\n",
            "Training Loss Epoch: 0.6716068928294322\n",
            "Training Accuracy Epoch: 55.88235294117647\n",
            "\n",
            "Training Loss per 5000 steps: 0.528016984462738\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 1: 70.7720588235294\n",
            "Training Loss Epoch: 0.5459445465136977\n",
            "Training Accuracy Epoch: 70.7720588235294\n",
            "\n",
            "Training Loss per 5000 steps: 0.23382768034934998\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 2: 80.88235294117646\n",
            "Training Loss Epoch: 0.38741928125348163\n",
            "Training Accuracy Epoch: 80.88235294117646\n",
            "\n",
            "Training Loss per 5000 steps: 0.32472506165504456\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 3: 86.94852941176471\n",
            "Training Loss Epoch: 0.3322992899509914\n",
            "Training Accuracy Epoch: 86.94852941176471\n",
            "\n",
            "Training Loss per 5000 steps: 0.17166589200496674\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 4: 88.6029411764706\n",
            "Training Loss Epoch: 0.2723725181730354\n",
            "Training Accuracy Epoch: 88.6029411764706\n",
            "\n",
            "Training Loss per 5000 steps: 0.04447651654481888\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 5: 92.83088235294117\n",
            "Training Loss Epoch: 0.18011405210777678\n",
            "Training Accuracy Epoch: 92.83088235294117\n",
            "\n",
            "Training Loss per 5000 steps: 0.4963013529777527\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 6: 95.58823529411765\n",
            "Training Loss Epoch: 0.12794441480518265\n",
            "Training Accuracy Epoch: 95.58823529411765\n",
            "\n",
            "Training Loss per 5000 steps: 0.09556420892477036\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 7: 94.8529411764706\n",
            "Training Loss Epoch: 0.13292886343140922\n",
            "Training Accuracy Epoch: 94.8529411764706\n",
            "\n",
            "Training Loss per 5000 steps: 0.04767290875315666\n",
            "Training Accuracy per 5000 steps: 100.0\n",
            "The Total Accuracy for Epoch 8: 95.58823529411765\n",
            "Training Loss Epoch: 0.12661546319106812\n",
            "Training Accuracy Epoch: 95.58823529411765\n",
            "\n",
            "Training Loss per 5000 steps: 0.6468261480331421\n",
            "Training Accuracy per 5000 steps: 75.0\n",
            "The Total Accuracy for Epoch 9: 95.58823529411765\n",
            "Training Loss Epoch: 0.1186190060329596\n",
            "Training Accuracy Epoch: 95.58823529411765\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,fold_nr):\n",
        "  print(\"\\nEntering FOLD NR. \", i)\n",
        "  for epoch in range(EPOCHS):\n",
        "    train(epoch,model[i],optimizer[i],training_loader[i])\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the test set on the fine-tuned model."
      ],
      "metadata": {
        "id": "6_1zvnOBUXYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the validation section to print the accuracy and see how it performs')\n",
        "print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n",
        "for i in range(0,fold_nr):\n",
        "  print(\"\\nEntering FOLD NR. \", i)\n",
        "  acc = valid(model[i], testing_loader[i])\n",
        "  print(\"Accuracy on test data = %0.2f%%\" % acc)\n",
        ""
      ],
      "metadata": {
        "id": "-TqE0rGlUXBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NB per Error Analysis. In df è contenuto il df shufflato.\n",
        "# Lo split 5-fold prevede che al fold 0 il test è costituito dal primo 20% di df. Al fold 4 il test è il 20% finale di df.\n",
        "\n",
        "\n",
        "f = open(\"misclassified_samples.txt\", \"a\")\n",
        "for i in range(0,fold_nr):\n",
        "  counter = 0\n",
        "  print(\"Fold \",i)\n",
        "  f.write('\\n'+\"Fold \"+str(i)+'\\n')\n",
        "  for _, data in enumerate(testing_loader[i], 0):\n",
        "            counter+=1\n",
        "            #print(\"\\n\\nSTEP Nr. \", nb_tr_steps)\n",
        "            # Validation batch is 2. Then, every step is 2 predictions. Then the total steps are half of the size of the test fold.\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.long)\n",
        "            #print(\"ids è\", ids)\n",
        "            #print(\"mask è\", mask)\n",
        "            outputs = model[i](ids, mask).squeeze()\n",
        "            #print(\"ids-> \",data['ids'] )\n",
        "            predicted = outputs.cpu().data.numpy().argmax()\n",
        "            actual = data['targets'].cpu().data.numpy()[0]\n",
        "            result_string = str(\"SAMPLE \"+str(counter)+\": targets-> \")\n",
        "            result_string +=(str(actual)+\" outputs-> \"+str(predicted)+'\\n')\n",
        "\n",
        "            #print(\"SAMPLE \",counter,\": targets-> \",data['targets'].cpu().data.numpy()[0], \"outputs-> \",outputs.cpu().data.numpy().argmax(),\"\\n\") #\" original out:\",outputs,\"\\n\")\n",
        "            if predicted!=actual:\n",
        "              print(\"SAMPLE \",counter,\": targets-> \",data['targets'].cpu().data.numpy()[0], \"outputs-> \",outputs.cpu().data.numpy().argmax(),\"\\n\") #\" original out:\",outputs,\"\\n\")\n",
        "              f.write(result_string)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q45Lwrz7d0em",
        "outputId": "22b550eb-cd11-445e-9d96-53058b5a5362"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold  0\n",
            "SAMPLE  3 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  6 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  9 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  26 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  29 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  33 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  35 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  36 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  39 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  53 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  70 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  71 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  80 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  92 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  97 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  107 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  113 : targets->  1 outputs->  0 \n",
            "\n",
            "Fold  1\n",
            "SAMPLE  3 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  16 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  17 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  21 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  28 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  34 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  41 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  46 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  66 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  68 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  74 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  75 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  83 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  92 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  96 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  101 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  104 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  111 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  113 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  134 : targets->  1 outputs->  0 \n",
            "\n",
            "Fold  2\n",
            "SAMPLE  1 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  2 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  3 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  9 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  13 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  21 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  23 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  25 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  37 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  38 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  66 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  67 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  82 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  83 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  89 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  101 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  102 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  117 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  123 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  126 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  130 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  134 : targets->  0 outputs->  1 \n",
            "\n",
            "Fold  3\n",
            "SAMPLE  6 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  21 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  39 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  44 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  46 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  49 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  50 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  55 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  59 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  60 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  65 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  66 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  72 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  75 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  83 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  85 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  91 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  95 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  97 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  105 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  106 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  112 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  118 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  121 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  123 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  130 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  131 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  135 : targets->  1 outputs->  0 \n",
            "\n",
            "Fold  4\n",
            "SAMPLE  15 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  16 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  20 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  23 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  25 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  27 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  39 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  50 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  60 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  69 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  89 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  91 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  100 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  110 : targets->  1 outputs->  0 \n",
            "\n",
            "SAMPLE  130 : targets->  0 outputs->  1 \n",
            "\n",
            "SAMPLE  135 : targets->  1 outputs->  0 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLbwK-Mrg94v"
      },
      "source": [
        "# Saving the Trained Model Artifacts for inference\n",
        "\n",
        "This is the final step in the process of fine tuning the model.\n",
        "\n",
        "The model and its vocabulary are saved locally. These files are then used in the future to make inference on new inputs of news headlines.\n",
        "\n",
        "Please remember that a trained neural network is only useful when used in actual inference after its training.\n",
        "\n",
        "In the lifecycle of an ML projects this is only half the job done. We will leave the inference of these models for some other day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "492L-lBBg94v"
      },
      "outputs": [],
      "source": [
        "# Saving the files for re-use\n",
        "\n",
        "output_model_file = './models/pytorch_distilbert_news.bin'\n",
        "output_vocab_file = './models/vocab_distilbert_news.bin'\n",
        "\n",
        "model_to_save = model\n",
        "torch.save(model_to_save, output_model_file)\n",
        "tokenizer.save_vocabulary(output_vocab_file)\n",
        "\n",
        "print('All files saved')\n",
        "print('This tutorial is completed')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}