{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-siino/GM_SOURCE_CODE/blob/main/AMD_DS/Prompting_Mistral_Large_Heterogeneus_Device_Mapping_DS_Devmap_AMD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional experiments for EAAI Submission. Prompt engineering for device mapping (GPU vs CPU) using Mistral Large."
      ],
      "metadata": {
        "id": "lawXqkf1QEQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mistralai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from mistralai import Mistral\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Inizializza Mistral API\n",
        "client = Mistral(api_key='7yOu0lH5XcZC1U2ZUI2uv0ghBDduhHp5')\n",
        "model = \"mistral-large-latest\"\n",
        "\n",
        "# Carica dataset\n",
        "df = pd.read_csv(\"/content/dataset-devmap-amd.csv\")\n",
        "df = df[[\"src\", \"oracle\"]]  # src = codice, oracle = label (\"CPU\"/\"GPU\")\n",
        "\n",
        "# Mapping etichette\n",
        "text_to_label = {\"CPU\": 0, \"GPU\": 1}\n",
        "label_to_text = {0: \"CPU\", 1: \"GPU\"}\n",
        "\n",
        "# Seed per riproducibilità\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Setup K-Fold\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(df[\"src\"], df[\"oracle\"])):\n",
        "    print(f\"\\nFold {fold + 1}\")\n",
        "    train_df = df.iloc[train_idx]\n",
        "    val_df = df.iloc[val_idx]\n",
        "\n",
        "    # Prompt iniziale con istruzioni\n",
        "    few_shot_prompt = (\n",
        "        \"Classify whether the following OpenCL kernel should run on CPU or GPU based on its characteristics.\\n\"\n",
        "        \"The label should be either 'CPU' or 'GPU'.\\n\\n\"\n",
        "    )\n",
        "\n",
        "    # Seleziona 5 esempi few-shot\n",
        "    few_shot_samples = train_df.sample(n=5, random_state=fold)\n",
        "    for _, row in few_shot_samples.iterrows():\n",
        "        few_shot_prompt += f\"Code:\\n{row['src']}\\nLabel: {row['oracle']}\\n\\n\"\n",
        "\n",
        "    preds = []\n",
        "    golds = []\n",
        "    texts = []\n",
        "\n",
        "    for i, (code_snippet, true_label) in enumerate(zip(val_df[\"src\"], val_df[\"oracle\"])):\n",
        "        print(\"\\n######### Avvio Predizione Numero \"+str(i)+\" del validation set relativo al FOLD \" +str(fold) + \" ###########\")\n",
        "        golds.append(text_to_label[true_label])\n",
        "        prompt = few_shot_prompt + f\"Code:\\n{code_snippet}\\nLabel:\"\n",
        "        message = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "        try:\n",
        "            chat_response = client.chat.complete(\n",
        "                model=model,\n",
        "                messages=message\n",
        "            )\n",
        "            completion = chat_response.choices[0].message.content.strip()\n",
        "\n",
        "            # Normalizzazione\n",
        "            if \"gpu\" in completion.lower():\n",
        "                pred_label = 1\n",
        "            elif \"cpu\" in completion.lower():\n",
        "                pred_label = 0\n",
        "            else:\n",
        "                pred_label = random.choice([0, 1])  # fallback\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Errore nella predizione: {e}\")\n",
        "            pred_label = random.choice([0, 1])\n",
        "\n",
        "        preds.append(pred_label)\n",
        "        texts.append(completion)\n",
        "        print(f\"[{i}] Pred: {label_to_text[pred_label]} | True: {true_label} | GPT output: {completion}\")\n",
        "        print(\"\\n######### PREDIZIONE TERMINATA. Numero \"+str(i)+\" del validation set relativo al FOLD \" +str(fold) + \" ###########\")\n",
        "\n",
        "    # Accuracy e confusion matrix\n",
        "    acc = accuracy_score(golds, preds)\n",
        "    print(f\"Fold {fold + 1} accuracy: {acc:.4f}\")\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    cm = confusion_matrix(golds, preds, labels=[0, 1])\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"CPU\", \"GPU\"])\n",
        "    disp.plot(cmap=\"Blues\")\n",
        "    plt.title(f\"Fold {fold + 1} Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "# Media finale\n",
        "print(f\"\\nAverage accuracy over all folds: {np.mean(accuracies):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhg3HiR6UKgr",
        "outputId": "3e61d28b-9c15-47e2-d526-107ce9ad1131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-1.9.2-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.11.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (4.14.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
            "Downloading mistralai-1.9.2-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: eval-type-backport, mistralai\n",
            "Successfully installed eval-type-backport-0.2.2 mistralai-1.9.2\n",
            "\n",
            "Fold 1\n",
            "\n",
            "######### Avvio Predizione Numero 0 del validation set relativo al FOLD 0 ###########\n",
            "[0] Pred: GPU | True: GPU | GPT output: To determine whether an OpenCL kernel should run on a CPU or GPU, we need to consider several factors:\n",
            "\n",
            "1. **Data Parallelism**: Kernels that perform the same operation on large datasets are typically better suited for GPUs.\n",
            "2. **Memory Access Patterns**: GPUs are more efficient with coalesced memory accesses.\n",
            "3. **Computational Intensity**: Kernels with high computational intensity (many arithmetic operations per memory access) generally perform better on GPUs.\n",
            "4. **Control Flow**: Kernels with complex control flow (e.g., many branches, loops) might perform better on CPUs.\n",
            "5. **Use of Local Memory**: Kernels that use local memory efficiently can benefit from GPU execution.\n",
            "\n",
            "Let's analyze each kernel:\n",
            "\n",
            "### Kernel 1\n",
            "```c\n",
            "__kernel void A(__global double* a, __global double* b, __global double* c, __local double* d, int e, int f, int g, int h) {\n",
            "  int i, j, k;\n",
            "  double l = 0.0;\n",
            "\n",
            "  j = get_global_id(0) + g;\n",
            "  k = get_local_id(0);\n",
            "\n",
            "  if (j < h) {\n",
            "    __global double(*m)[12 + 2] = (__global double(*)[12 + 2])a;\n",
            "    __global double(*n)[12 + 2] = (__global double(*)[12 + 2])b;\n",
            "\n",
            "    for (i = e; i < f; i++) {\n",
            "      l = l + (m[j][i] + m[j][i + 1] + m[j + 1][i] + m[j + 1][i + 1] + n[j][i] + n[j][i + 1] + n[j + 1][i] + n[j + 1][i + 1]);\n",
            "    }\n",
            "  }\n",
            "  d[k] = l;\n",
            "\n",
            "  barrier(1);\n",
            "\n",
            "  if (k == 0) {\n",
            "    for (i = 1; i < get_local_size(0); i++) {\n",
            "      l += d[i];\n",
            "    }\n",
            "\n",
            "    c[get_group_id(0)] = l;\n",
            "  }\n",
            "}\n",
            "```\n",
            "**Characteristics**:\n",
            "- Uses local memory efficiently.\n",
            "- Involves a reduction operation.\n",
            "- Moderate computational intensity.\n",
            "\n",
            "**Label**: **GPU**\n",
            "\n",
            "### Kernel 2\n",
            "```c\n",
            "__kernel void A(__global double* a, __global double* b, __global double* c, __global double* d, __global double* e) {\n",
            "  int f = get_global_id(0);\n",
            "  if (f >= (128 + 1))\n",
            "    return;\n",
            "\n",
            "  a[f] = 0.0;\n",
            "  b[f] = 0.0;\n",
            "  double g = d[f];\n",
            "  c[f] = g;\n",
            "  e[f] = g;\n",
            "}\n",
            "```\n",
            "**Characteristics**:\n",
            "- Simple element-wise operations.\n",
            "- Minimal computational intensity.\n",
            "\n",
            "**Label**: **CPU**\n",
            "\n",
            "### Kernel 3\n",
            "```c\n",
            "extern void B(__private float, __private float3, __private float3 *);\n",
            "extern float C(__private float3);\n",
            "extern float D(__private float, __private float, __private float);\n",
            "extern float E(__private float, __private float);\n",
            "\n",
            "__kernel void A(__global float* a, __global float* b, __global float* c, int d) {\n",
            "  const int e = get_global_id(0);\n",
            "  if (e >= d)\n",
            "    return;\n",
            "\n",
            "  float f = a[e + 0 * d];\n",
            "  float3 g;\n",
            "  g.x = a[e + (1 + 0) * d];\n",
            "  g.y = a[e + (1 + 1) * d];\n",
            "  g.z = a[e + (1 + 2) * d];\n",
            "\n",
            "  float h = a[e + (1 + 3) * d];\n",
            "\n",
            "  float3 i;\n",
            "  B(f, g, &i);\n",
            "  float j = C(i);\n",
            "\n",
            "  float k = D(f, h, j);\n",
            "  float l = E(f, k);\n",
            "\n",
            "  c[e] = (float)(0.5f) / (sqrt(b[e]) * (sqrt(j) + l));\n",
            "}\n",
            "```\n",
            "**Characteristics**:\n",
            "- Heavy use of external functions.\n",
            "- Complex operations and memory access patterns.\n",
            "\n",
            "**Label**: **CPU**\n",
            "\n",
            "### Kernel 4\n",
            "```c\n",
            "extern void B(double, double, double, double*, __global double *);\n",
            "\n",
            "__kernel void A(__global double* a, __global double* b, int c, int d, int e) {\n",
            "  int f, g, h, i;\n",
            "  double j, k, l, m[5];\n",
            "\n",
            "  h = get_global_id(1);\n",
            "  g = get_global_id(0);\n",
            "  if (h >= e || g >= d)\n",
            "    return;\n",
            "\n",
            "  __global double(*n)[12 / 2 * 2 + 1][12 / 2 * 2 + 1][5] = (__global double(*)[12 / 2 * 2 + 1][12 / 2 * 2 + 1][5])a;\n",
            "\n",
            "  l = (double)h * (1.0 / (double)(12 - 1));\n",
            "  k = (double)g * (1.0 / (double)(12 - 1));\n",
            "\n",
            "  f = 0;\n",
            "  j = 0.0;\n",
            "  B(j, k, l, m, b);\n",
            "  for (i = 0; i < 5; i++) {\n",
            "    n[h][g][f][i] = m[i];\n",
            "  }\n",
            "\n",
            "  f = c - 1;\n",
            "  j = 1.0;\n",
            "  B(j, k, l, m, b);\n",
            "  for (i = 0; i < 5; i++) {\n",
            "    n[h][g][f][i] = m[i];\n",
            "  }\n",
            "}\n",
            "```\n",
            "**Characteristics**:\n",
            "- Uses external functions.\n",
            "- Complex memory access patterns.\n",
            "\n",
            "**Label**: **CPU**\n",
            "\n",
            "### Kernel 5\n",
            "```c\n",
            "__kernel void A(__global float* a, __global float* b, __global float* c, int d) {\n",
            "  int e = get_global_id(0);\n",
            "\n",
            "  if (e < d) {\n",
            "    int f;\n",
            "    for (f = 0; f < d; f++) {\n",
            "      b[e] += a[f * d + e] * c[f];\n",
            "    }\n",
            "  }\n",
            "}\n",
            "```\n",
            "**Characteristics**:\n",
            "- Simple matrix-vector multiplication.\n",
            "- High data parallelism.\n",
            "\n",
            "**Label**: **GPU**\n",
            "\n",
            "### Kernel 6\n",
            "```c\n",
            "__kernel void A(int a, const __global float4* b, __global float4* c, __local float4* d, __local float4* e) {\n",
            "  unsigned int f = get_local_id(0);\n",
            "  unsigned int g = get_group_id(0);\n",
            "\n",
            "  float4 h = b[g];\n",
            "\n",
            "  float4 i = (1.0f - h) * 5.0f + h * 30.f;\n",
            "  float4 j = (1.0f - h) * 1.0f + h * 100.f;\n",
            "  float4 k = (1.0f - h) * 0.25f + h * 10.f;\n",
            "  float4 l = k * (1.0f / (float)a);\n",
            "  float4 m = 0.30f * sqrt(l);\n",
            "  float4 n = 0.02f * l;\n",
            "  float4 o = exp(n);\n",
            "  float4 p = 1.0f / o;\n",
            "  float4 q = exp(m);\n",
            "  float4 r = 1.0f / q;\n",
            "  float4 s = (o - r) / (q - r);\n",
            "  float4 t = 1.0f - s;\n",
            "  float4 u = s * p;\n",
            "  float4 v = t * p;\n",
            "\n",
            "  float4 w = i * exp(m * (2.0f * f - (float)a)) - j;\n",
            "  d[f].x = w.x > 0 ? w.x : 0.0f;\n",
            "  d[f].y = w.y > 0 ? w.y : 0.0f;\n",
            "  d[f].z = w.z > 0 ? w.z : 0.0f;\n",
            "  d[f].w = w.w > 0 ? w.w : 0.0f;\n",
            "\n",
            "  barrier(1);\n",
            "\n",
            "  for (int x = a; x > 0; x -= 2) {\n",
            "    if (f < x) {\n",
            "      e[f] = u * d[f] + v * d[f + 1];\n",
            "    }\n",
            "    barrier(1);\n",
            "\n",
            "    if (f < x - 1) {\n",
            "      d[f] = u * e[f] + v * e[f + 1];\n",
            "    }\n",
            "    barrier(1);\n",
            "  }\n",
            "\n",
            "  if (f == 0)\n",
            "    c[g] = d[0];\n",
            "}\n",
            "```\n",
            "**Characteristics**:\n",
            "- Complex mathematical operations.\n",
            "- Uses local memory efficiently.\n",
            "- Moderate computational intensity.\n",
            "\n",
            "**Label**: **GPU**\n",
            "\n",
            "### Summary\n",
            "- **Kernel 1**: **GPU**\n",
            "- **Kernel 2**: **CPU**\n",
            "- **Kernel 3**: **CPU**\n",
            "- **Kernel 4**: **CPU**\n",
            "- **Kernel 5**: **GPU**\n",
            "- **Kernel 6**: **GPU**\n",
            "\n",
            "######### PREDIZIONE TERMINATA. Numero 0 del validation set relativo al FOLD 0 ###########\n",
            "\n",
            "######### Avvio Predizione Numero 1 del validation set relativo al FOLD 0 ###########\n",
            "[1] Pred: GPU | True: GPU | GPT output: To classify whether the OpenCL kernels should run on CPU or GPU, we need to consider factors such as the level of parallelism, memory access patterns, and computational intensity. Here are the labels for each kernel:\n",
            "\n",
            "### Kernel 1\n",
            "```c\n",
            "__kernel void A(__global double* a, __global double* b, __global double* c, __local double* d, int e, int f, int g, int h) {\n",
            "  int i, j, k;\n",
            "  double l = 0.0;\n",
            "\n",
            "  j = get_global_id(0) + g;\n",
            "  k = get_local_id(0);\n",
            "\n",
            "  if (j < h) {\n",
            "    __global double(*m)[12 + 2] = (__global double(*)[12 + 2])a;\n",
            "    __global double(*n)[12 + 2] = (__global double(*)[12 + 2])b;\n",
            "\n",
            "    for (i = e; i < f; i++) {\n",
            "      l = l + (m[j][i] + m[j][i + 1] + m[j + 1][i] + m[j + 1][i + 1] + n[j][i] + n[j][i + 1] + n[j + 1][i] + n[j + 1][i + 1]);\n",
            "    }\n",
            "  }\n",
            "  d[k] = l;\n",
            "\n",
            "  barrier(1);\n",
            "\n",
            "  if (k == 0) {\n",
            "    for (i = 1; i < get_local_size(0); i++) {\n",
            "      l += d[i];\n",
            "    }\n",
            "\n",
            "    c[get_group_id(0)] = l;\n",
            "  }\n",
            "}\n",
            "```\n",
            "**Label: GPU**\n",
            "\n",
            "**Explanation:** This kernel performs a significant amount of parallel computation with local memory usage and barrier synchronization, which are well-suited for GPU execution.\n",
            "\n",
            "### Kernel 2\n",
            "```c\n",
            "__kernel void A(__global double* a, __global double* b, __global double* c, __global double* d, __global double* e) {\n",
            "  int f = get_global_id(0);\n",
            "  if (f >= (128 + 1))\n",
            "    return;\n",
            "\n",
            "  a[f] = 0.0;\n",
            "  b[f] = 0.0;\n",
            "  double g = d[f];\n",
            "  c[f] = g;\n",
            "  e[f] = g;\n",
            "}\n",
            "```\n",
            "**Label: CPU**\n",
            "\n",
            "**Explanation:** This kernel performs simple, non-intensive operations that can be efficiently handled by the CPU. The operations are not computationally intensive and do not benefit significantly from the massive parallelism of a GPU.\n",
            "\n",
            "### Kernel 3\n",
            "```c\n",
            "extern void B(__private float, __private float3, __private float3 *);\n",
            "extern float C(__private float3);\n",
            "extern float D(__private float, __private float, __private float);\n",
            "extern float E(__private float, __private float);\n",
            "\n",
            "__kernel void A(__global float* a, __global float* b, __global float* c, int d) {\n",
            "  const int e = get_global_id(0);\n",
            "  if (e >= d)\n",
            "    return;\n",
            "\n",
            "  float f = a[e + 0 * d];\n",
            "  float3 g;\n",
            "  g.x = a[e + (1 + 0) * d];\n",
            "  g.y = a[e + (1 + 1) * d];\n",
            "  g.z = a[e + (1 + 2) * d];\n",
            "\n",
            "  float h = a[e + (1 + 3) * d];\n",
            "\n",
            "  float3 i;\n",
            "  B(f, g, &i);\n",
            "  float j = C(i);\n",
            "\n",
            "  float k = D(f, h, j);\n",
            "  float l = E(f, k);\n",
            "\n",
            "  c[e] = (float)(0.5f) / (sqrt(b[e]) * (sqrt(j) + l));\n",
            "}\n",
            "```\n",
            "**Label: CPU**\n",
            "\n",
            "**Explanation:** This kernel involves several function calls and complex operations that might not be efficiently handled by a GPU. The CPU is better suited for handling the complexity and potential branching.\n",
            "\n",
            "### Kernel 4\n",
            "```c\n",
            "extern void B(double, double, double, double*, __global double *);\n",
            "\n",
            "__kernel void A(__global double* a, __global double* b, int c, int d, int e) {\n",
            "  int f, g, h, i;\n",
            "  double j, k, l, m[5];\n",
            "\n",
            "  h = get_global_id(1);\n",
            "  g = get_global_id(0);\n",
            "  if (h >= e || g >= d)\n",
            "    return;\n",
            "\n",
            "  __global double(*n)[12 / 2 * 2 + 1][12 / 2 * 2 + 1][5] = (__global double(*)[12 / 2 * 2 + 1][12 / 2 * 2 + 1][5])a;\n",
            "\n",
            "  l = (double)h * (1.0 / (double)(12 - 1));\n",
            "  k = (double)g * (1.0 / (double)(12 - 1));\n",
            "\n",
            "  f = 0;\n",
            "  j = 0.0;\n",
            "  B(j, k, l, m, b);\n",
            "  for (i = 0; i < 5; i++) {\n",
            "    n[h][g][f][i] = m[i];\n",
            "  }\n",
            "\n",
            "  f = c - 1;\n",
            "  j = 1.0;\n",
            "  B(j, k, l, m, b);\n",
            "  for (i = 0; i < 5; i++) {\n",
            "    n[h][g][f][i] = m[i];\n",
            "  }\n",
            "}\n",
            "```\n",
            "**Label: CPU**\n",
            "\n",
            "**Explanation:** This kernel involves complex memory access patterns and function calls, which are better suited for CPU execution due to the complexity and potential branching.\n",
            "\n",
            "### Kernel 5\n",
            "```c\n",
            "__kernel void A(__global float* a, __global float* b, __global float* c, int d) {\n",
            "  int e = get_global_id(0);\n",
            "\n",
            "  if (e < d) {\n",
            "    int f;\n",
            "    for (f = 0; f < d; f++) {\n",
            "      b[e] += a[f * d + e] * c[f];\n",
            "    }\n",
            "  }\n",
            "}\n",
            "```\n",
            "**Label: GPU**\n",
            "\n",
            "**Explanation:** This kernel performs a matrix-vector multiplication, which is a highly parallelizable operation well-suited for GPU execution.\n",
            "\n",
            "### Kernel 6\n",
            "```c\n",
            "__kernel void A(__global uchar4* a, __global uchar4* b) {\n",
            "  uint c = get_global_id(0);\n",
            "  uint d = get_global_id(1);\n",
            "\n",
            "  uint e = get_global_size(0);\n",
            "  uint f = get_global_size(1);\n",
            "\n",
            "  float4 g = (float4)(0);\n",
            "  float4 h = g;\n",
            "\n",
            "  int i = c + d * e;\n",
            "\n",
            "  if (c >= 1 && c < (e - 1) && d >= 1 && d < f - 1) {\n",
            "    float4 j = convert_float4(a[i - 1 - e]);\n",
            "    float4 k = convert_float4(a[i - e]);\n",
            "    float4 l = convert_float4(a[i + 1 - e]);\n",
            "    float4 m = convert_float4(a[i - 1]);\n",
            "    float4 n = convert_float4(a[i]);\n",
            "    float4 o = convert_float4(a[i + 1]);\n",
            "    float4 p = convert_float4(a[i - 1 + e]);\n",
            "    float4 q = convert_float4(a[i + e]);\n",
            "    float4 r = convert_float4(a[i + 1 + e]);\n",
            "\n",
            "    g = j + (float4)(2) * k + l - p - (float4)(2) * q - r;\n",
            "\n",
            "    h = j - l + (float4)(2) * m - (float4)(2) * o + p - r;\n",
            "\n",
            "    b[i] = convert_uchar4(hypot(g, h) / (float4)(2));\n",
            "  }\n",
            "}\n",
            "```\n",
            "**Label: GPU**\n",
            "\n",
            "**Explanation:** This kernel performs image processing operations that are highly parallelizable and well-suited for GPU execution due to the need for concurrent processing of image pixels.\n",
            "\n",
            "### Summary\n",
            "- **Kernel 1:** GPU\n",
            "- **Kernel 2:** CPU\n",
            "- **Kernel 3:** CPU\n",
            "- **Kernel 4:** CPU\n",
            "- **Kernel 5:** GPU\n",
            "- **Kernel 6:** GPU\n",
            "\n",
            "######### PREDIZIONE TERMINATA. Numero 1 del validation set relativo al FOLD 0 ###########\n",
            "\n",
            "######### Avvio Predizione Numero 2 del validation set relativo al FOLD 0 ###########\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BguZGFr6PxN1",
        "_Q0ZQeyMcUkC",
        "mu02IYtIcgJt",
        "p7YS5LPKRdX5"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}